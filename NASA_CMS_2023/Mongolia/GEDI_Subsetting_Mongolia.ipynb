{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c865be-f3c0-486d-96f6-f549464f9b11",
   "metadata": {},
   "source": [
    "### For loops to pull L2A, L2B, L4A as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175a4417-2226-45f1-bcdd-b6aafd7460e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/envs/pangeo/lib/python3.10/site-packages (0.14.2)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopandas) (1.9.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopandas) (24.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopandas) (2.1.4)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopandas) (3.5.0)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopandas) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting contextily\n",
      "  Using cached contextily-1.6.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: geopy in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (3.7.3)\n",
      "Requirement already satisfied: mercantile in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (1.2.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (10.0.0)\n",
      "Requirement already satisfied: rasterio in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (1.3.7)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (2.31.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (1.4.0)\n",
      "Requirement already satisfied: xyzservices in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from contextily) (2024.4.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from geopy->contextily) (2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from matplotlib->contextily) (2.9.0)\n",
      "Requirement already satisfied: click>=3.0 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from mercantile->contextily) (8.1.7)\n",
      "Requirement already satisfied: affine in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (2024.2.2)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (0.7.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from rasterio->contextily) (69.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from requests->contextily) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from requests->contextily) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from requests->contextily) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pangeo/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.16.0)\n",
      "Using cached contextily-1.6.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: contextily\n",
      "Successfully installed contextily-1.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "!pip install contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b8daec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.maap-project.org')\n",
    "\n",
    "def job_status_for(job_id: str) -> str:\n",
    "    response = maap.getJobStatus(job_id)\n",
    "    response.raise_for_status()\n",
    "   \n",
    "    root = ET.fromstring(response.text)\n",
    "    status_element = root.find('.//{http://www.opengis.net/wps/2.0}Status')\n",
    "   \n",
    "    return status_element.text\n",
    "\n",
    "def job_result_for(job_id: str) -> str:\n",
    "    response = maap.getJobResult(job_id)\n",
    "    response.raise_for_status()\n",
    "   \n",
    "    root = ET.fromstring(response.text)\n",
    "\n",
    "    return root.find('.//{http://www.opengis.net/wps/2.0}Data').text\n",
    "\n",
    "def to_job_output_dir(job_result_url: str) -> str:\n",
    "    url_path = urlparse(job_result_url).path\n",
    "    # The S3 Key is the URL path excluding the `/{username}` prefix\n",
    "    s3_key = \"/\".join(url_path.split(\"/\")[2:])\n",
    "\n",
    "    return f\"/projects/my-private-bucket/{s3_key}\"\n",
    "\n",
    "def wait_for_job(job_id: str) -> str:\n",
    "    return job_status_for(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfe988a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install geopandas\n",
    "#pip install shapely\n",
    "#Import numpy for making column inputs easier\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import backoff\n",
    "import shapely\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6f1642-ce8d-400f-aa52-e81450dc86dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def job_status_for(job_id: str) -> str:\n",
    "    response = maap.getJobStatus(job_id)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    root = ET.fromstring(response.text)\n",
    "    status_element = root.find('.//{http://www.opengis.net/wps/2.0}Status')\n",
    "    \n",
    "    return status_element.text\n",
    "\n",
    "def job_result_for(job_id: str) -> str:\n",
    "    response = maap.getJobResult(job_id)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    root = ET.fromstring(response.text)\n",
    "\n",
    "    return root.find('.//{http://www.opengis.net/wps/2.0}Data').text\n",
    "\n",
    "def to_job_output_dir(job_result_url: str) -> str:\n",
    "    url_path = urlparse(job_result_url).path\n",
    "    # The S3 Key is the URL path excluding the `/{username}` prefix\n",
    "    s3_key = \"/\".join(url_path.split(\"/\")[2:])\n",
    "\n",
    "    return f\"/projects/my-private-bucket/{s3_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9ee896-3729-4c3f-893f-231f993330ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2866 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2866.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2952 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2952.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2787 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2787.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2951 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2951.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2867 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2867.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2630 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2630.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2788 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2788.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2868 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2868.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2706 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2706.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2629 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2629.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2707 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2707.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2708 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2708.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2786 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2786.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2166 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2166.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2165 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2165.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2021 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2021.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2024 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2024.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 2022 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2022.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buffered feature with fid 1953 to /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1953.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172/3874193231.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m input_gpkg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/Uvs_Boreal_Tiles.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your input GeoPackage\u001b[39;00m\n\u001b[1;32m     37\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the directory where you want to save the split files\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43msplit_gpkg_with_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_gpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36msplit_gpkg_with_buffer\u001b[0;34m(input_gpkg, output_dir, buffer_distance)\u001b[0m\n\u001b[1;32m     25\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.gpkg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Write the single feature with buffer to its own GeoPackage\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43msingle_feature_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPKG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved buffered feature with fid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/geopandas/geodataframe.py:1264\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \n\u001b[1;32m   1175\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \n\u001b[1;32m   1261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1264\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/geopandas/io/file.py:612\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 612\u001b[0m     \u001b[43m_to_file_fiona\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    614\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/geopandas/io/file.py:638\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[0;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m crs:\n\u001b[1;32m    637\u001b[0m     crs_wkt \u001b[38;5;241m=\u001b[39m crs\u001b[38;5;241m.\u001b[39mto_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWKT1_GDAL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 638\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfiona\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m colxn:\n\u001b[1;32m    641\u001b[0m     colxn\u001b[38;5;241m.\u001b[39mwriterecords(df\u001b[38;5;241m.\u001b[39miterfeatures())\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/fiona/__init__.py:303\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    293\u001b[0m         path,\n\u001b[1;32m    294\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode string must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/site-packages/fiona/collection.py:246\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n\u001b[0;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1169\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/pangeo/lib/python3.10/locale.py:657\u001b[0m, in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _get_locale_encoding()\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# On Unix, if CODESET is available, use that.\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetpreferredencoding\u001b[39m(do_setlocale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    658\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Return the charset that the user is likely using,\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;124;03m        according to the system configuration.\"\"\"\u001b[39;00m\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mutf8_mode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def split_gpkg_with_buffer(input_gpkg, output_dir, buffer_distance=0.1):\n",
    "    # Load the GeoPackage into a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_gpkg)\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Iterate through each feature (row) in the GeoDataFrame\n",
    "    for index, row in gdf.iterrows():\n",
    "        # Extract the 'fid' value (assuming the column name is 'fid')\n",
    "        fid_value = row['tile_num']\n",
    "        \n",
    "        # Create a new GeoDataFrame for the single feature\n",
    "        single_feature_gdf = gpd.GeoDataFrame([row], crs=gdf.crs)\n",
    "        single_feature_gdf = single_feature_gdf.to_crs(epsg=4326)\n",
    "        \n",
    "        # Add a 0.1 degree buffer to the geometry of the feature\n",
    "        single_feature_gdf['geometry'] = single_feature_gdf['geometry'].buffer(buffer_distance)\n",
    "        \n",
    "        # Construct the output file path using the 'fid' value\n",
    "        output_file = os.path.join(output_dir, f\"{fid_value}.gpkg\")\n",
    "        \n",
    "        # Write the single feature with buffer to its own GeoPackage\n",
    "        single_feature_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "        print(f\"Saved buffered feature with fid {fid_value} to {output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "input_gpkg = '/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/Selenge_Boreal_Tiles.gpkg'  # Replace with the path to your input GeoPackage\n",
    "output_dir = '/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES'  # Replace with the directory where you want to save the split files\n",
    "split_gpkg_with_buffer(input_gpkg, output_dir)\n",
    "\n",
    "input_gpkg = '/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/Uvs_Boreal_Tiles.gpkg'  # Replace with the path to your input GeoPackage\n",
    "output_dir = '/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES'  # Replace with the directory where you want to save the split files\n",
    "split_gpkg_with_buffer(input_gpkg, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cd9744-0aa1-4875-a906-1f6d51fac51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the folder path containing the tiles\n",
    "# #folder_path = \"/projects/my-public-bucket/AOIs/GHANA/\"\n",
    "# folder_path = \"/projects/my-public-bucket/Data/NASA_CMS_2023/WA_15_countries/\"\n",
    "\n",
    "# # Create a list to store the GeoPackage file paths\n",
    "# json_files = []\n",
    "\n",
    "# # Use glob to find all .gpkg files in the folder\n",
    "# #pattern = os.path.join(folder_path, '*.geojson')\n",
    "# pattern = os.path.join(folder_path, 'Mali_South.gpkg')\n",
    "# json_files = glob.glob(pattern)\n",
    "\n",
    "# # Print the list of GeoPackage file paths\n",
    "# #for file_path in gpkg_files:\n",
    "#  #   print(file_path)\n",
    "\n",
    "# #json_files = [x.replace('/projects/my-public-bucket/AOIs/GHANA/',\n",
    "# #                        'https://maap-ops-workspace.s3.amazonaws.com/shared/leitoldv/AOIs/GHANA/') for x in json_files]\n",
    "# json_files = [x.replace('/projects/my-public-bucket/Data/NASA_CMS_2023/WA_15_countries/',\n",
    "#                         'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/WA_15_countries/') for x in json_files]\n",
    "\n",
    "# print(len(json_files))\n",
    "# print(json_files)\n",
    "# AOIs = json_files\n",
    "# AOIs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eeb7754-293f-428b-91a4-b708075fef4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # OPTIONAL # visually verify the AOI\n",
    "# aoi = AOIs[0]\n",
    "\n",
    "# try:\n",
    "#     import geopandas as gpd\n",
    "#     import contextily as ctx\n",
    "# except:\n",
    "#     print(\n",
    "#         \"If you wish to visually verify your AOI, \"\n",
    "#         \"you must install the `geopandas` and `contextily` packages.\"\n",
    "#     )\n",
    "# else:\n",
    "#     aoi_gdf = gpd.read_file(aoi)\n",
    "#     aoi_epsg4326 = aoi_gdf.to_crs(epsg=4326)\n",
    "#     ax = aoi_epsg4326.plot(figsize=(10, 5), alpha=0.3, edgecolor=\"red\")\n",
    "#     ctx.add_basemap(ax, crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc4e72-38fa-4971-a819-275c3598963b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aoi_name = os.path.basename(AOIs[0]).split('.')[0]\n",
    "# aoi_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59bab5d-9978-4684-9356-5f071f695288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "['https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1883.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1884.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1952.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1953.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1954.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/1955.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2021.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2022.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2023.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2024.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2091.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2092.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2093.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2094.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2165.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2166.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2629.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2630.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2706.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2707.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2708.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2786.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2787.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2788.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2866.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2867.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2868.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2951.gpkg', 'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/2952.gpkg']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES\"\n",
    "json_files = []\n",
    "pattern = os.path.join(folder_path, '*.gpkg')\n",
    "json_files = glob.glob(pattern)\n",
    "json_files = [ x for x in json_files if \"L2A\" not in x ]\n",
    "json_files = [x.replace('/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/',\n",
    "                        'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/MONGOLIA/GRID_TILES/') for x in json_files]\n",
    "print(len(json_files))\n",
    "print(json_files)\n",
    "AOIs = json_files\n",
    "\n",
    "# folder_path = \"/projects/my-public-bucket/Data/NASA_CMS_2023/WA_15_countries/GRID_Mali/\"\n",
    "# json_files = []\n",
    "# pattern = os.path.join(folder_path, '*.gpkg')\n",
    "# json_files = glob.glob(pattern)\n",
    "# json_files = [ x for x in json_files if \"L2A\" not in x ]\n",
    "# json_files = [x.replace('/projects/my-public-bucket/Data/NASA_CMS_2023/WA_15_countries/GRID_Mali/',\n",
    "#                         'https://maap-ops-workspace.s3.amazonaws.com/shared/nehajo88/Data/NASA_CMS_2023/WA_15_countries/GRID_Mali/') for x in json_files]\n",
    "# print(len(json_files))\n",
    "# print(json_files)\n",
    "# AOIs = json_files\n",
    "# AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1148dc4-6335-452f-91eb-9215504ed072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks, I'll run the GEDI L2A subsetter for 2093!!\n"
     ]
    }
   ],
   "source": [
    "#Set up run to pull products for all GEDI products simultaneously #To run for only 1 or 2 products, change \"PRODUCTS\"\n",
    "\n",
    "PRODUCTS = [\"L2A\",\"L4A\"] # ,\"L2A\",\"L2B\"]  #To run for only 1 or 2 products, change \"PRODUCTS\"\n",
    "out_dir = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/\"\n",
    "\n",
    "AOIs = json_files\n",
    "#AOIs = [AOIs[2]]\n",
    "\n",
    "for each_aoi in AOIs: \n",
    "    if \"L4A\" in PRODUCTS: \n",
    "        if not os.path.exists(out_dir + f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L4A.gpkg\"):\n",
    "            aoi_name = os.path.basename(each_aoi).split('.')[0]\n",
    "            print(f\"Thanks, I'll run the GEDI L4A subsetter for {aoi_name}!!\")\n",
    "            #aoi_url = each_aoi\n",
    "            inputs = dict(\n",
    "               aoi=each_aoi,\n",
    "               doi=\"L4A\",\n",
    "               lat=\"lat_lowestmode\",\n",
    "               lon=\"lon_lowestmode\",\n",
    "               beams=\"all\",\n",
    "               columns=\"shot_number,lat_lowestmode,lon_lowestmode,elev_lowestmode,agbd,agbd_se,agbd_t,agbd_t_se,sensitivity,geolocation/sensitivity_a2\",\n",
    "               query=\"l2_quality_flag == 1 and l4_quality_flag == 1 and sensitivity > 0.95\", #  and geolocation/sensitivity_a2 > 0.95\",\n",
    "               limit = 100000,\n",
    "               #temporal=\"-\",\n",
    "               output=f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L4A.gpkg\"\n",
    "            )\n",
    "            result = maap.submitJob(\n",
    "                identifier=\"gedi-subset\",\n",
    "                algo_id=\"gedi-subset\",\n",
    "                version=\"0.9.0\",\n",
    "                queue=\"maap-dps-worker-32vcpu-64gb\",\n",
    "                username=\"nehajo88\",\n",
    "                **inputs\n",
    "            )\n",
    "            inputs\n",
    "            job_id = result.id\n",
    "            job_id or result\n",
    "\n",
    "    if \"L2B\" in PRODUCTS: \n",
    "        if not os.path.exists(out_dir + f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L2B.gpkg\"):\n",
    "            aoi_name = os.path.basename(each_aoi).split('.')[0]\n",
    "            print(f\"Thanks, I'll run the GEDI L2B subsetter for {aoi_name}!!\")\n",
    "            #aoi_url = each_aoi\n",
    "            inputs = dict(\n",
    "               aoi=each_aoi,\n",
    "               doi=\"L2B\",\n",
    "               lat=\"geolocation/lat_lowestmode\",\n",
    "               lon=\"geolocation/lon_lowestmode\",\n",
    "               beams=\"all\",\n",
    "               columns=\"shot_number,geolocation/lon_lowestmode,geolocation/lat_lowestmode,rh100,l2b_quality_flag,sensitivity,cover,land_cover_data/landsat_treecover, pai,fhd_normal,\"+\",\".join(variables),\n",
    "               query=\"l2a_quality_flag == 1 and l2b_quality_flag == 1 and sensitivity > 0.95\",\n",
    "               limit = 100000,\n",
    "               #temporal=\"-\",\n",
    "               output=f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L2B.gpkg\"\n",
    "            )\n",
    "            result = maap.submitJob(\n",
    "                identifier=\"gedi-subset\",\n",
    "                algo_id=\"gedi-subset\",\n",
    "                version=\"0.9.0\",\n",
    "                queue=\"maap-dps-worker-32vcpu-64gb\",\n",
    "                username=\"nehajo88\",\n",
    "                **inputs\n",
    "            )\n",
    "            inputs\n",
    "            job_id = result.id\n",
    "            job_id or result\n",
    "        \n",
    "        \n",
    "    if \"L2A\" in PRODUCTS: \n",
    "        if not os.path.exists(out_dir + f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L2A.gpkg\"):\n",
    "            aoi_name = os.path.basename(each_aoi).split('.')[0]\n",
    "            print(f\"Thanks, I'll run the GEDI L2A subsetter for {aoi_name}!!\")\n",
    "            #aoi_url = each_aoi\n",
    "            inputs = dict(\n",
    "               aoi=each_aoi,\n",
    "               doi=\"L2A\",\n",
    "               lat=\"lat_lowestmode\",\n",
    "               lon=\"lon_lowestmode\",\n",
    "               beams=\"all\",\n",
    "               columns=\"shot_number,lon_lowestmode,lat_lowestmode,rh10,rh20,rh30,rh40,rh50,rh60,rh70,rh80,rh90,rh98,quality_flag,sensitivity\",\n",
    "               # columns=\"shot_number,lon_lowestmode,lat_lowestmode,rh10,rh20,rh30,rh40,rh50,rh60,rh70,rh80,rh90,rh98,quality_flag,rx_processing_a2/rx_algrunflag,rx_processing_a2/zcross,rx_processing_a2/toploc,geolocation/sensitivity_a2,degrade_f\",\n",
    "               #columns=\"all\",\n",
    "               query=\"quality_flag == 1 and sensitivity > 0.95\",\n",
    "               limit = 100000,\n",
    "               #temporal=\"-\",\n",
    "               output=f\"{os.path.basename(each_aoi).split('.')[0]}_MON_L2A.gpkg\"\n",
    "            )\n",
    "            result = maap.submitJob(\n",
    "                identifier=\"gedi-subset\",\n",
    "                algo_id=\"gedi-subset\",\n",
    "                version=\"0.9.0\",\n",
    "                queue=\"maap-dps-worker-32gb\",\n",
    "                username=\"nehajo88\",\n",
    "                **inputs\n",
    "            )\n",
    "            inputs\n",
    "            job_id = result.id\n",
    "            job_id or result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483f2aaf-990f-4461-a3f0-e81815885cec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/my-private-bucket/dps_output/gedi-subset/0.9.0/gedi-subset/2024/12/04/20/30/30/564761/2093_MON_L2A.gpkg\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2093_MON_L2A.gpkg\n",
      "Moving 2093_MON_L2A.gpkg...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "root_dir = \"/projects/my-private-bucket/dps_output/gedi-subset/0.9.0/gedi-subset/2024/12/04\"  # Can now set name\n",
    "out_dir = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/\"\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(root_dir):\n",
    "#    print(\"Found directory: %s\" % dirName)\n",
    "    for fname in fileList:\n",
    "        if fname.endswith(\"_MON_L2A.gpkg\") or fname.endswith(\"_MON_L4A.gpkg\"):\n",
    "#        if fname.endswith(\"NPAs_L4A.gpkg\"):\n",
    "            source_path = os.path.join(dirName, fname)\n",
    "            print(source_path)\n",
    "            target_path = os.path.join(out_dir, fname)\n",
    "            print(target_path)\n",
    "            if not os.path.exists(target_path):  # Check if file doesnt exist in target directory\n",
    "                print(f\"Moving {fname}...\")\n",
    "                subprocess.call(['mv', source_path, target_path])\n",
    "            else:\n",
    "                print(f\"{fname} already exists in the target directory. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6adb9002-f628-479c-94b5-ed8ff24a56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1883_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1884_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1952_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1953_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1954_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/1955_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2021_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2022_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2023_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2024_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2091_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2092_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2093_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2094_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2165_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2166_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2629_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2630_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2706_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2707_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2708_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2786_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2787_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2788_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2866_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2867_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2868_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2951_MON_L2A.tif\n",
      "GeoTIFF exists\n",
      "/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/2952_MON_L2A.tif\n",
      "GeoTIFF exists\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import argparse\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.rio import options\n",
    "from rasterio.shutil import copy, delete\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rio_cogeo.cogeo import cog_translate\n",
    "from rio_cogeo.profiles import cog_profiles\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "FOLDER = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/\"\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(FOLDER):\n",
    "    for fname in fileList:\n",
    "        if fname.endswith(\"_MON_L2A.gpkg\") and not fname.__contains__(\"ADM1\"):\n",
    "            OUTFILE = os.path.join(FOLDER, fname.split('.')[0] + '.tif')\n",
    "            print(OUTFILE)\n",
    "            \n",
    "            if not os.path.exists(OUTFILE): \n",
    "                L2A = gpd.read_file(os.path.join(FOLDER, fname))\n",
    "                L2A = L2A.drop('geometry', axis=1)\n",
    "                \n",
    "                x = L2A[\"lon_lowestmode\"]\n",
    "                y = L2A[\"lat_lowestmode\"]\n",
    "                z = L2A.rh98\n",
    "                # z[z == 0] = np.nan  # Replace 0 values with NaN for 'no data' handling\n",
    "                \n",
    "                pixel_width = 0.004  # units in degrees\n",
    "                pixel_height = 0.004  # units in degrees\n",
    "                \n",
    "                nx = int(np.round((np.max(x) - np.min(x)) / pixel_width))  # x size of output raster\n",
    "                ny = int(np.round((np.max(y) - np.min(y)) / pixel_width))  # y size of output raster\n",
    "                \n",
    "                zi, yi, xi = np.histogram2d(y, x, bins=(ny, nx), weights=z)\n",
    "                counts, _, _ = np.histogram2d(y, x, bins=(ny, nx))\n",
    "                \n",
    "                # Calculate mean value (avoid divide by 0 errors)\n",
    "                zi = np.divide(zi, counts, out=np.zeros_like(zi), where=counts != 0)\n",
    "                \n",
    "                # Reverse array to match coordinate system\n",
    "                z = np.array(zi.data[::-1])\n",
    "                \n",
    "                # Set NaN values to 0 in the array (nodata handling)\n",
    "                z[np.isnan(z)] = 0  # Replace NaN values with 0\n",
    "\n",
    "                pixel_width = xi[1] - xi[0]  # Approximate pixel width\n",
    "                pixel_height = yi[1] - yi[0]  # Approximate pixel height\n",
    "                x_min = xi[0]\n",
    "                y_max = yi[-1]\n",
    "                \n",
    "                transform = from_origin(x_min, y_max, pixel_width, pixel_height)\n",
    "                crs = CRS.from_epsg(4326)\n",
    "                \n",
    "                kwargs = {\n",
    "                    'driver': 'GTiff',\n",
    "                    'dtype': z.dtype,\n",
    "                    'count': 1,  # Number of bands\n",
    "                    'height': z.shape[0],\n",
    "                    'width': z.shape[1],\n",
    "                    'crs': crs,\n",
    "                    'transform': transform,\n",
    "                    'predictor': 2,\n",
    "                    'nodata': 0  # Set the nodata value to 0\n",
    "                }\n",
    "                \n",
    "                with MemoryFile() as memfile:\n",
    "                    with memfile.open(**kwargs) as mem:\n",
    "                        # Write data with 'nodata' set to 0\n",
    "                        mem.write(z.reshape(1, z.shape[0], z.shape[1]))\n",
    "                \n",
    "                        dst_profile = cog_profiles.get(\"deflate\")\n",
    "                        cog_translate(\n",
    "                            mem,\n",
    "                            OUTFILE,\n",
    "                            dst_profile,\n",
    "                            in_memory=False\n",
    "                        )\n",
    "                \n",
    "                print(\"GeoTIFF has been created successfully with GDAL.\")\n",
    "            else:\n",
    "                print(\"GeoTIFF exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57a6da30-b944-425c-b2e8-3ea7f5874bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merge successful. Output saved to: /projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/GEDI_L2A_Uvs.tif\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for axis 1 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m input_files\n\u001b[1;32m    122\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/GEDI_L2A_Uvs.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_file): merge_rasters_with_average(input_files, output_file)\n",
      "Cell \u001b[0;32mIn[44], line 42\u001b[0m, in \u001b[0;36mmerge_rasters_with_average\u001b[0;34m(input_files, output_file, data_type, compression, predictor, zlevel)\u001b[0m\n\u001b[1;32m     39\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(optfile_path)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Now, we average the overlapping regions, ignoring NoData values (treated as 0)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43maverage_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 84\u001b[0m, in \u001b[0;36maverage_raster\u001b[0;34m(merged_raster_path, input_files)\u001b[0m\n\u001b[1;32m     81\u001b[0m data \u001b[38;5;241m=\u001b[39m band\u001b[38;5;241m.\u001b[39mReadAsArray()\n\u001b[1;32m     82\u001b[0m nodata \u001b[38;5;241m=\u001b[39m nodata_values[idx]\n\u001b[0;32m---> 84\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# If the value is NoData (or 0, since we convert NoData to 0), skip it\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;241m==\u001b[39m nodata:  \u001b[38;5;66;03m# Ignore NoData\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for axis 1 with size 58"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "\n",
    "def merge_rasters_with_average(input_files, output_file, data_type='Float32', compression='DEFLATE', predictor=2, zlevel=9):\n",
    "    # Create a temporary directory for the optfile\n",
    "    temp_dir = os.path.dirname(output_file)\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    \n",
    "    # Create the optfile containing the list of input files\n",
    "    optfile_path = os.path.join(temp_dir, 'mergeInputFiles.txt')\n",
    "    with open(optfile_path, 'w') as optfile:\n",
    "        for file in input_files:\n",
    "            optfile.write(f\"{file}\\n\")\n",
    "    \n",
    "    # Prepare the gdal_merge.py command to merge the rasters\n",
    "    gdal_merge_command = [\n",
    "        'gdal_merge.py',\n",
    "        '-ot', data_type,\n",
    "        '-of', 'GTiff',\n",
    "        '-co', f'COMPRESS={compression}',\n",
    "        '-co', f'PREDICTOR={predictor}',\n",
    "        '-co', f'ZLEVEL={zlevel}',\n",
    "        '-o', output_file,\n",
    "        '--optfile', optfile_path\n",
    "    ]\n",
    "    \n",
    "    # Run the command using subprocess\n",
    "    try:\n",
    "        subprocess.run(gdal_merge_command, check=True)\n",
    "        print(f\"Merge successful. Output saved to: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during merge: {e}\")\n",
    "    finally:\n",
    "        # Clean up the optfile\n",
    "        if os.path.exists(optfile_path):\n",
    "            os.remove(optfile_path)\n",
    "    \n",
    "    # Now, we average the overlapping regions, ignoring NoData values (treated as 0)\n",
    "    average_raster(output_file, input_files)\n",
    "\n",
    "\n",
    "def average_raster(merged_raster_path, input_files):\n",
    "    # Open the merged raster using GDAL\n",
    "    ds = gdal.Open(merged_raster_path, gdal.GA_Update)\n",
    "    if ds is None:\n",
    "        print(f\"Failed to open raster: {merged_raster_path}\")\n",
    "        return\n",
    "\n",
    "    # Read raster data into an array\n",
    "    band = ds.GetRasterBand(1)  # Assuming a single band raster\n",
    "    raster_data = band.ReadAsArray()\n",
    "\n",
    "    # Get the raster dimensions\n",
    "    rows, cols = raster_data.shape\n",
    "\n",
    "    # Create an empty array for the averaged values and count of valid pixels\n",
    "    average_data = np.zeros_like(raster_data, dtype=np.float32)\n",
    "    count_data = np.zeros_like(raster_data, dtype=np.int32)\n",
    "\n",
    "    # Loop through the input rasters to get their NoData values\n",
    "    nodata_values = []\n",
    "    for file in input_files:\n",
    "        src_ds = gdal.Open(file)\n",
    "        if src_ds is None:\n",
    "            print(f\"Failed to open raster: {file}\")\n",
    "            continue\n",
    "        band = src_ds.GetRasterBand(1)  # Assuming single band raster\n",
    "        nodata = band.GetNoDataValue()\n",
    "        nodata_values.append(nodata)\n",
    "\n",
    "    # Iterate over the merged raster data to perform averaging\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            values_to_average = []\n",
    "            for idx, file in enumerate(input_files):\n",
    "                src_ds = gdal.Open(file)\n",
    "                band = src_ds.GetRasterBand(1)\n",
    "                data = band.ReadAsArray()\n",
    "                nodata = nodata_values[idx]\n",
    "\n",
    "                value = data[i, j]\n",
    "\n",
    "                # If the value is NoData (or 0, since we convert NoData to 0), skip it\n",
    "                if nodata is not None and value == nodata:  # Ignore NoData\n",
    "                    value = 0  # Convert NoData to 0\n",
    "                if value != 0:  # Ignore 0 values (representing NoData in this context)\n",
    "                    values_to_average.append(value)\n",
    "\n",
    "            # If we have valid values, compute the average\n",
    "            if values_to_average:\n",
    "                average_data[i, j] = np.mean(values_to_average)\n",
    "                count_data[i, j] = len(values_to_average)\n",
    "\n",
    "    # Set the NoData value for pixels where there were no valid data points\n",
    "    average_data[count_data == 0] = -9999  # Adjust NoData value if needed\n",
    "\n",
    "    # Write the averaged data back to the raster\n",
    "    band.WriteArray(average_data)\n",
    "    band.SetNoDataValue(-9999)  # Set the NoData value\n",
    "    ds = None\n",
    "    print(f\"Averaging complete. The output is saved in {merged_raster_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     folder_path = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/\"\n",
    "#     json_files = []\n",
    "#     pattern = os.path.join(folder_path, '*MON_L2A.tif')\n",
    "#     input_files = glob.glob(pattern)[0:16]\n",
    "#     input_files\n",
    "#     output_file = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/GEDI_L2A_Selenge.tif\"\n",
    "    \n",
    "#     if not os.path.exists(output_file): merge_rasters_with_average(input_files, output_file)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/\"\n",
    "    json_files = []\n",
    "    pattern = os.path.join(folder_path, '*MON_L2A.tif')\n",
    "    input_files = glob.glob(pattern)[16:]\n",
    "    input_files\n",
    "    output_file = \"/projects/my-public-bucket/Data/NASA_CMS_2023/MONGOLIA/GRID/GEDI_L2A_Uvs.tif\"\n",
    "    \n",
    "    if not os.path.exists(output_file): merge_rasters_with_average(input_files, output_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
